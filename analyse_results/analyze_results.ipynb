{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from model import *\n",
    "from pathlib import Path\n",
    "from module import * \n",
    "import altair as alt\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "import torch \n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from  pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'train'\n",
    "for dataset_type in [\"train\", \"val\", \"test\"]:\n",
    "    ground_truth = 'normal'\n",
    "    data_path = f\"/kaggle/input/final-hdf5-files/filtered_chunk1_{dataset_type}.hdf5\"\n",
    "    h5_file = h5py.File(data_path, \"r\")\n",
    "    keys = list(h5_file.keys())\n",
    "    person_seq = {}\n",
    "    print(len(keys), 'comma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze distance prediction error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze error per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = \"none\" #Originally \"resnet\"\n",
    "dataset = \"comma\"\n",
    "bs = 1\n",
    "gpu_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target, mask, reduction=\"mean\"):\n",
    "        out = (input[~mask]-target[~mask])**2\n",
    "        return out.mean() if reduction == \"mean\" else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(logits, angle, distance, multitask):\n",
    "        print(angle, distance, logits)\n",
    "        if multitask == \"multitask\":\n",
    "            logits_angle = torch.tensor([l[0] for l in logits])\n",
    "            logits_dist = torch.tensor([l[1] for l in logits])\n",
    "            mask = (distance > 40) | (distance == 0)\n",
    "            loss_angle = torch.sqrt(mse_loss(logits_angle.squeeze(), angle.squeeze(), mask))\n",
    "            loss_distance = torch.sqrt(mse_loss(logits_dist.squeeze(), distance.squeeze(), mask))\n",
    "            loss = loss_angle, loss_distance\n",
    "            return loss_angle, loss_distance\n",
    "        elif multitask == \"angle\":\n",
    "            mask = distance.squeeze() == 0.0 \n",
    "            loss = torch.sqrt(mse_loss(logits.squeeze(), angle.squeeze(), mask))\n",
    "            return loss\n",
    "        elif multitask == \"distance\":\n",
    "            mask = (distance > 40)  | (distance == 0)\n",
    "            loss = torch.sqrt(mse_loss(logits.squeeze(), angle.squeeze(), mask))\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regular_ckpt_from_lightning_checkpoint(state_dict):\n",
    "    try:\n",
    "        new_sd = {}\n",
    "        for k, v in state_dict.items():\n",
    "            nk = k.replace(\"model.\", \"\") if k.startswith(\"model.\") else k\n",
    "            new_sd[nk] = v\n",
    "        return new_sd\n",
    "    except Exception:\n",
    "        return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type='distance'\n",
    "\n",
    "ckpt_root = f\"/kaggle/working/ckpts_final_comma_{type}_none_True_1\"\n",
    "#find the latest version -G.R.\n",
    "versions = glob.glob(os.path.join(ckpt_root, \"lightning_logs\", \"version_*\"))\n",
    "if not versions:\n",
    "    raise FileNotFoundError(\"None found\")\n",
    "latest_version = max(versions, key=os.path.getmtime)\n",
    "\n",
    "# Find checkpoints in the latest version -G.R.\n",
    "ckpt_files = glob.glob(os.path.join(latest_version, \"checkpoints\", \"*.ckpt\"))\n",
    "if not ckpt_files:\n",
    "    raise FileNotFoundError(\"None found.\")\n",
    "checkpoint_path = max(ckpt_files, key=os.path.getmtime)\n",
    "\n",
    "print(f\"Using checkpoint: {checkpoint_path}\")\n",
    "\n",
    "ckpt = torch.load(checkpoint_path)\n",
    "state_dict = ckpt['state_dict']\n",
    "state_dict = get_regular_ckpt_from_lightning_checkpoint(state_dict)\n",
    "#added this to load the model correctly -G.R.\n",
    "#model.load_state_dict(state_dict)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_pth_angle = f\"/kaggle/working/ckpts_final_comma_angle_none_True_1\"\n",
    "ckpt_pth_distance = f'/kaggle/working/ckpts_final_comma_distance_none_True_1'\n",
    "ckpt_pth_multitask = f'/kaggle/working/ckpts_final_comma_multitask_none_True_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(logits, target, save_name, path):\n",
    "    df = pd.DataFrame()\n",
    "    df['logits'] = logits.squeeze().tolist()\n",
    "    df['target'] = target.squeeze().tolist()\n",
    "    df.to_csv(f'./{path}/{save_name}.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASs the prediction csv\n",
    "\n",
    "p_conceptClip = \"/kaggle/working/comma_distance_none_True_100_clip.csv\"\n",
    "p_retinanet = \"/kaggle/working/comma_distance_none_True_100_retinanet.csv\"\n",
    "ps = [p_conceptClip,p_retinanet]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_concept = \"/kaggle/working/comma_distance_none_True_100_clip.csv\"\n",
    "df = pd.read_csv(p_concept, header=None)\n",
    "df.columns = ['preds', 'targets']\n",
    "\n",
    "m = (df['targets'] > 40).astype(bool)  | (df['targets'] == 0).astype(bool) \n",
    "loss1 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "m = (df['targets'] > 50).astype(bool)  | (df['targets'] == 0).astype(bool) \n",
    "loss2 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "m = (df['targets'] > 60).astype(bool)  | (df['targets'] == 0).astype(bool) \n",
    "loss3 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "print(loss1.item(), loss2.item(), loss3.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing with angle/distance desidered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_concept = '/data1/shared/jessica/data3/data/toyota/ckpts/ckpts_desirednuscenes_distance/lightning_logs/version_6/distance.csv'\n",
    "p_concept_resnet = '/data1/shared/jessica/data3/data/toyota/ckpts/ckpts_desirednuscenes_distance/lightning_logs/version_7/distance.csv'\n",
    "p_resnet = '/data1/shared/jessica/data3/data/toyota/ckpts/ckpts_desirednuscenes_distance/lightning_logs/version_9/distance.csv'\n",
    "ps = [p_concept, p_resnet, p_concept_resnet]\n",
    "for p in ps: \n",
    "    print(p)\n",
    "    df = pd.read_csv(p, header=None)\n",
    "    df.columns = ['preds', 'targets']\n",
    "\n",
    "    m = (df['targets'] > 40).astype(bool)  | (df['targets'] == 0).astype(bool) \n",
    "    loss1 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "    m = (df['targets'] > 50).astype(bool)  | (df['targets'] == 0).astype(bool) \n",
    "    loss2 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "    m = (df['targets'] > 60).astype(bool)  | (df['targets'] == 0).astype(bool) \n",
    "    loss3 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "    print(loss1.item(), loss2.item(), loss3.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1.item(), loss2.item(), loss3.item()#dist multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1.item(), loss2.item(), loss3.item()#dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([\"<40\", \"<50\", \"<60\"], [loss1.item(), loss2.item(), loss3.item()])\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['distance'] = res['distance']\n",
    "df['angle'] = res['angle']\n",
    "df['driver'] = range(len(res['angle']))\n",
    "alt.Chart(df).mark_circle(size=60).encode(\n",
    "    x=alt.X('distance',scale=alt.Scale(domain=(0, 16))),\n",
    "    y=alt.Y('angle',scale=alt.Scale(domain=(0, 3))),\n",
    "    tooltip=['driver']\n",
    ").interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(zip(*res[\"multitask\"]))\n",
    "z = l[1]\n",
    "y = l[0]\n",
    "df = pd.DataFrame()\n",
    "df['distance'] = z\n",
    "df['distance'] = df['distance'].apply(lambda x: x.item())\n",
    "df['angle'] = y\n",
    "df['angle'] = df['angle'].apply(lambda x: x.item())\n",
    "df['driver'] = range(len(y))\n",
    "alt.Chart(df).mark_circle(size=60).encode(\n",
    "    x='distance',\n",
    "    y='angle',\n",
    "    tooltip=['driver']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT THE RIGHT PREDS PATH\n",
    "preds_path = '/kaggle/working/comma_distance_none_True_100_clip.csv'\n",
    "#preds_path=f'/data1/jessica/data/toyota/ckpts/ckpts_desiredcomma_distance/lightning_logs/version_1/dist.csv'\n",
    "df = pd.read_csv(preds_path)\n",
    "df.columns = ['preds', 'targets']\n",
    "df = df[df['targets'] != 0]\n",
    "df['err'] = df['targets'] - df['preds']\n",
    "ten = df[df['targets'] < 10]\n",
    "six = df[df['targets'] > 60]\n",
    "twen = df[(df['targets'] > 10 & (df['targets'] < 20))]\n",
    "four = df[(df['targets'] > 20 & (df['targets'] < 40))]\n",
    "fift = df[(df['targets'] > 40 & (df['targets'] < 60))]\n",
    "ndf = {}\n",
    "ndf[\"<10\"] = ten['err'].tolist()\n",
    "ndf[\"10-20\"] = twen['err'].tolist()\n",
    "ndf[\"20-40\"] = four['err'].tolist()\n",
    "ndf[\"40-60\"] = fift['err'].tolist()\n",
    "ndf[\">60\"] = six['err'].tolist()\n",
    "my_dict = ndf\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(my_dict.values())\n",
    "ax.set_xticklabels(my_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
